{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"From the given business card image, extract available information in json format as follows:\n",
    "```json\n",
    "{\n",
    "  \"name\": \"John Doe\",\n",
    "  \"title\": \"CEO\",\n",
    "  \"company\": \"Company Name\",\n",
    "  \"address\": \"1234 Street Name, City, Country\",\n",
    "  \"email\": \"\",\n",
    "  \"phone\": \"\"\n",
    "}\n",
    "```\n",
    "Keep fields empty if the information is not available.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "image_path = \"business_card.jpg\"\n",
    "with open(image_path, \"rb\") as image_file:\n",
    "    image = image_file.read()\n",
    "\n",
    "data = {\n",
    "    \"instruction\": prompt,\n",
    "}\n",
    "\n",
    "files={\n",
    "    \"image\": image\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"json_output\": True\n",
    "}\n",
    "\n",
    "url = \"http://localhost:5000/vision\"\n",
    "response =  requests.post(url,params=params,data=data, files=files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Mariana Anderson',\n",
       " 'title': 'Marketing Manager',\n",
       " 'company': 'Really Great Site',\n",
       " 'address': '123 Anywhere St., Any City, ST 12345',\n",
       " 'email': 'hello@reallygreatsite.com',\n",
       " 'phone': '+123-456-7890'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write me a poem about Machine Learning.\n",
      "\n",
      "A tapestry of data, woven tight,\n",
      "A million threads of knowledge, shining bright.\n",
      "Algorithms dance, a rhythmic sway,\n",
      "Learning patterns, come what may.\n",
      "\n",
      "From pixels to prose, a journey bold,\n",
      "Predicting futures, stories untold.\n",
      "With every iteration, wisdom grows,\n",
      "Unveiling secrets, as the model flows.\n",
      "\n",
      "Neural networks, a web so deep,\n",
      "Connecting neurons, secrets to keep.\n",
      "Backpropagation whispers, a guiding light,\n",
      "Optimizing parameters, day and night.\n",
      "\n",
      "But caution whispers, a gentle plea,\n",
      "Bias and fairness, we must all agree.\n",
      "For in the mirror, our own flaws we see,\n",
      "Reflecting back, the data's decree.\n",
      "\n",
      "So let us build, with care and grace,\n",
      "Machines that learn, at a steady pace.\n",
      "With ethical compass, guiding our way,\n",
      "Towards a future, where AI holds sway. \n",
      "\n",
      "\n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "# pip install accelerate\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['HF_TOKEN'] = \"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\"\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b-it\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"google/gemma-2-2b-it\",\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos>Write 5 facts about narendra modi.\n",
      "\n",
      "Here are 5 facts about Narendra Modi:\n",
      "\n",
      "1. **Born in Gujarat:** Narendra Modi was born in Vadnagar, Gujarat, on September 17, 1950.\n",
      "2. **Early Career:** He began his career as a tea seller and later worked as a chemist and a businessman.\n",
      "3. **Political Rise:** Modi entered politics in 1991 and rose to prominence as the Chief Minister of Gujarat.\n",
      "4. **Prime Minister of India:** He became the Prime Minister of India in 2014, leading the Bharatiya Janata Party (BJP) to a historic victory.\n",
      "5. **Global Recognition:** Modi has received international recognition for his leadership and has been invited to address global summits and conferences.\n",
      "\n",
      "\n",
      "Let me know if you'd like to know more about him! \n",
      "<end_of_turn>\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Write 5 facts about narendra modi\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=256)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
